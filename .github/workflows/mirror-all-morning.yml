name: Mirror ALL sheets (header-safe)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 12 * * 1-5"   # 08:00 Toronto, weekdays

permissions:
  contents: write

jobs:
  mirror_all:
    runs-on: ubuntu-latest
    env:
      SHEET_ID: 1iClfgrC4QaJ7Wb00dPoeg6DANCc1VisSqds-yhXtL2M
      OUT_DIR: sheets         # where CSVs will land
      EXCLUDE_RX: ""          # e.g., "^(H_|TA_)" to skip those
      HEADER_ROW: "1"         # set to "2" if your headers live on row 2
      TZ: America/Toronto

    steps:
      - uses: actions/checkout@v4

      - name: Fetch workbook (XLSX)
        run: |
          set -euo pipefail
          mkdir -p tmp
          URL="https://docs.google.com/spreadsheets/d/${SHEET_ID}/export?format=xlsx"
          echo "Fetching workbook: $URL"
          curl -fSLo tmp/workbook.xlsx "$URL"
          ls -lh tmp/workbook.xlsx

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install openpyxl

      - name: Split each tab into its own CSV (respect HEADER_ROW)
        run: |
          set -euo pipefail
          python - << 'PY'
import csv, os, re, json
from openpyxl import load_workbook

sheet_id   = os.getenv("SHEET_ID")
out_dir    = os.getenv("OUT_DIR","sheets")
exclude_rx = os.getenv("EXCLUDE_RX","")
hdr_row    = int(os.getenv("HEADER_ROW","1"))  # 1-based index for the first row to export

ex = re.compile(exclude_rx) if exclude_rx else None
os.makedirs(out_dir, exist_ok=True)

wb = load_workbook("tmp/workbook.xlsx", data_only=True, read_only=True)
names = [n for n in wb.sheetnames if not (ex and ex.search(n))]
pad = len(str(len(names)))

index = []
for i, name in enumerate(names, 1):
    ws = wb[name]
    safe = re.sub(r'[^A-Za-z0-9._-]+', '_', name).strip('_') or f"Sheet_{i}"
    fname = f"{i:0{pad}d}_{safe}.csv"
    fpath = os.path.join(out_dir, fname)

    with open(fpath, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        for r_idx, row in enumerate(ws.iter_rows(values_only=True), start=1):
            if r_idx < hdr_row:
                continue  # skip banner/title rows above header
            r = list(row)
            # Trim trailing empties to keep CSV compact
            while r and (r[-1] is None or (isinstance(r[-1], str) and r[-1].strip() == "")):
                r.pop()
            w.writerow(["" if v is None else v for v in r])

    # stats for index
    try:
        with open(fpath, encoding="utf-8") as f:
            lines = sum(1 for _ in f)
    except Exception:
        lines = 0

    index.append({"order": i, "sheet": name, "file": fpath, "rows": lines})

# Write an index to browse outputs easily
with open(os.path.join(out_dir, "_index.json"), "w", encoding="utf-8") as f:
    json.dump(index, f, ensure_ascii=False, indent=2)

print(f"Wrote {len(names)} CSV files to {out_dir}")
for item in index:
    print(f"{item['order']:02d} {item['sheet']} -> {item['file']} ({item['rows']} lines)")
PY

      - name: Commit & push if changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Mirror ALL sheets (header-safe): $(date -u +'%Y-%m-%dT%H:%MZ')"
          file_pattern: ${{ env.OUT_DIR }}/*.csv ${{ env.OUT_DIR }}/_index.json

      - name: Upload artifact (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mirror-all-output
          path: |
            ${{ env.OUT_DIR }}/*.csv
            ${{ env.OUT_DIR }}/_index.json
          if-no-files-found: warn
